---
title: "Project4"
author: "Shariq Mian"
date: "11/15/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tm)
library(knitr)
library(plyr)
library(wordcloud)
library(tidyverse)
library(tm)
library(magrittr)
library(data.table)
library(e1071)
library(caret)
library(randomForest)
```

```{r}
ham="~/Shariq School/SPS/Data 607/SpamHam/easy_ham"
count_ham=length(list.files(path = ham))
ham_list=list.files(ham)
count_ham
```


```{r}
spam= "~/Shariq School/SPS/Data 607/SpamHam/spam_2"
count_spam=length(list.files(path = spam))
spam_list=list.files(spam)
count_spam
```

```{r}
spam_list=list.files(spam)
ham_text = NA
for(i in 1:length(ham_list))
{
  path=paste0(ham, "/", ham_list[1])  
  text =readLines(path)
  list= list(paste(text, collapse="\n"))
  ham_text = c(ham_text,list)
  
}

spam_text = NA
for(i in 1:length(spam_list))
{
  path=paste0(spam, "/", spam_list[1])  
  text =readLines(path)
  list= list(paste(text, collapse="\n"))
  spam_text = c(spam_text,list)
}
```

```{r}
email_body <- function(ham_text){
  message = str_split(ham_text,"\n\n") %>% unlist()
  body = paste(message[2:length(message)], collapse=' ' )
  return(body)
}

ham_text <- email_body(ham_text)
ham_text
```

# general filtering opts:

```{r}
# Building a new corpus
ham_corpus =VCorpus(VectorSource(unlist(lapply(ham_text, as.character))))
ham_terms_matrix = TermDocumentMatrix(ham_corpus,control= list(removePunctuation=TRUE, removeNumbers=TRUE, stripWhitespace=TRUE, stopwords=TRUE))
ham_corpus = tm_map(ham_corpus, removeNumbers)
ham_corpus = tm_map(ham_corpus, removeWords, stopwords())
ham_corpus = tm_map(ham_corpus, removePunctuation)
ham_corpus = tm_map(ham_corpus, stemDocument)
ham_corpus = tm_map(ham_corpus, stripWhitespace)
ham_terms_matrix = TermDocumentMatrix(ham_corpus)

spam_corpus= VCorpus(VectorSource(spam_text))
spam_terms_matrix= TermDocumentMatrix(spam_corpus,control=list(removePunctuation=TRUE, removeNumbers=TRUE, stripWhitespace=TRUE, stopwords=TRUE))
spam_corpus = tm_map(spam_corpus, removeNumbers)
spam_corpus = tm_map(spam_corpus, removeWords, stopwords())
spam_corpus = tm_map(spam_corpus, removePunctuation)
spam_corpus = tm_map(spam_corpus, stemDocument)
spam_corpus = tm_map(spam_corpus, stripWhitespace)
spam_terms_matrix = TermDocumentMatrix(spam_corpus)
```


```{r}
#ham_df =as.data.frame(unlist(ham_text),stringsAsFactors = FALSE)
#ham_df$type = "ham"
#colnames(ham_df) = c("text","Classification")
#ham_df


#spam_df =as.data.frame(unlist(spam_text),stringsAsFactors = FALSE)
#spam_df$type = "spam"
#colnames(spam_df) = c("text","Classification")
#spam_df
```

```{r}
spam_df = as.data.frame(as.table(spam_terms_matrix))
spam_df$spam_ham = "SPAM"
colnames(spam_df) = c('TERM', 'SPAM_DOCS', 'SPAM_FREQ', 'TYPE_SPAM')
spam_df = subset(spam_df, select = -c(2) )
spam_df$SPAM_FREQ[is.na(spam_df$SPAM_FREQ)] = '0'
spam_df = ddply(spam_df, .(TERM, TYPE_SPAM), summarize, SPAM_FREQ = sum(as.numeric(SPAM_FREQ)))
head(spam_df, n = 20)

ham_df = as.data.frame(as.table(ham_terms_matrix))
ham_df$spam_ham = "HAM"
colnames(ham_df) = c('TERM', 'HAM_DOCS', 'HAM_FREQ', 'TYPE_HAM')
ham_df = subset(ham_df, select = -c(2) )
ham_df$HAM_FREQ[is.na(ham_df$HAM_FREQ)] = '0'
ham_df = ddply(ham_df, .(TERM, TYPE_HAM), summarize, HAM_FREQ = sum(as.numeric(HAM_FREQ)))
head(ham_df, n = 20)
```

```{r}
# Bind the data frames
spam_ham_df = merge(x = ham_df, y = spam_df, by="TERM", all = TRUE)
nrow(spam_ham_df)
```

```{r}
spam_ham_df<- spam_ham_df[sample(nrow(spam_ham_df)),]
spam_ham_df
```

```{r}
wordcloud(ham_corpus, max.words = 200, random.order = FALSE, colors=c('green'))
```

```{r}
wordcloud(spam_corpus, max.words = 200, random.order = FALSE, colors=c('red'))
```

